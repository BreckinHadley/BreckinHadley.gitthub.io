[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Breckinn Hadley",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#title-breckinhadley.gitthub.io",
    "href": "index.html#title-breckinhadley.gitthub.io",
    "title": "My Document",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About Me:\nI am originally from Bainbridge Island, Washington, and I am currently pursuing a double major in Statistics/Data Science and Quantitative Economics at St. Olaf College in Northfield, Minnesota. In addition to my academic work, I am also a 4 year student-athlete on the St. Olaf baseball team.\nI am interested in applying quantitative methods to real-world decision-making, particularly within government analytics and the sports industry. I bring strong analytical skills, a disciplined work ethic, and experience balancing rigorous academic and athletic commitments. I am motivated by opportunities that allow me to leverage data to drive insight, strategy, and performance."
  },
  {
    "objectID": "Mini_Project1.html",
    "href": "Mini_Project1.html",
    "title": "Analysis of the original Star Wars Trilogy",
    "section": "",
    "text": "Overview:\nThis mini project uses text analysis and sentiment scoring to analyze the scripts of the original Star Wars trilogy (Episodes 4–6). By breaking up the dialogue and analyzing it using differnt sentiments (Bing, NRC, and AFINN), we can see the different trends in how emotions, word choice, and character dialogue changes throughout the original trilogy.\nThe project focuses on several questions: What words in the movies wave the highest positive or negative connotation? How are specific emotions, like fear and trust, expressed throughout the trilogy? Which characters have the most lines, and what words do they use the most? How does the emotional tone change throughout each movie, and how do the three movies compare to each other?\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: RColorBrewer\n\nLoading required package: viridisLite\n\n\n\n\nRows: 2523 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): name, line\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n# A tibble: 25,937 × 3\n   name     movie    word   \n   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;  \n 1 THREEPIO new_hope did    \n 2 THREEPIO new_hope you    \n 3 THREEPIO new_hope hear   \n 4 THREEPIO new_hope that   \n 5 THREEPIO new_hope they've\n 6 THREEPIO new_hope shut   \n 7 THREEPIO new_hope down   \n 8 THREEPIO new_hope the    \n 9 THREEPIO new_hope main   \n10 THREEPIO new_hope reactor\n# ℹ 25,927 more rows\n\n\nNegative and Positive Sentiment Scores (Eps. 4-6):\n\n\nJoining with `by = join_by(word)`\n\n\n\n\n\n\n\n\n\nFor this plot I want to know the top 10 most frequent positive words and top 10 most frequent negative words used in Star Wars Episodes 4-6. This code above produces a faceted bar chart to illustrate the results.\nFear and Trust Sentiment Scores (Eps. 4-6):\n\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(SW_tidy, nrc_sentiments): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 13 of `x` matches multiple rows in `y`.\nℹ Row 7863 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nInsights: This plot produces similar results as the plot above but looks at the top 10 most frequent trusting words and top 10 most frequent fearful words used in Star Wars Episodes 4-6. This code also uses a faceted bar chart to showcase the results.\nWord Lengths in Star Wars Dialogue:\n\n\n\n\n\n\n\n\n\nInsights: This plot shows how the word length compares to the sentiment while also showing what letter the word starts with. It seems that words that start with f,g,h, and i tend to have a more positive connotation while words starting with s,t,u,v have a more negative connotation.\nTop 10 Characters by Number of Lines in the Original Star Wars Trilogy:\n\n\n\n\n\n\n\n\n\nInsights: I wanted to compare the number of lines differnt characters had in Star Wars episodes 4-6. I decided to pick the top 10 characters with the most lines and display them on a horizonatal histogram.\nThis plot is a horizontal bar chart titled “Top 10 Characters by Number of Lines in the Original Star Wars Trilogy.” On the x-axis is the lists characters making the top 10, and on the y-axis we have the number of lines that character speaks through out the trilogy. The horizontal bars are colored green (like Lukes Lightsaber) and the characters are ordered from most lines at the top to least lines at the bottom. The character with the most lines in the trilogy is Luke and the character with the tenth most lines is Biggs.\n\n\n\n\n\n\n\n\nTop 10 Most Frequent Non-Stop Words\n\n\nStar Wars Dialogue Analysis\n\n\nWord\nCount\n\n\n\n\nluke\n132\n\n\nsir\n91\n\n\nartoo\n84\n\n\nchewie\n65\n\n\nship\n57\n\n\ntime\n56\n\n\nmaster\n52\n\n\nfather\n51\n\n\nvader\n51\n\n\nforce\n50\n\n\n\n\n\n\n\nInsights: For this code I wanted to find which word was said the most by each character. I had to account for stop_word (the,and,I,me, etc) but this were easily filtered out using anti_join.\nTheme throughtout the Trilogy\n\n\n\n\n\n\n\n\n\nInsights: This plot was one of my favorites to make. This is a sentiment trajectory plot for each Star Wars movie which basically shows the emotional trajectory for each of the films. All of the films seem to be relatively similar to one another with one not being dratically differnt from the others."
  },
  {
    "objectID": "Mapping.html",
    "href": "Mapping.html",
    "title": "Mapping",
    "section": "",
    "text": "Linking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nRows: 51 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): State\ndbl (1): Pollution\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 51 × 2\n   State                Pollution\n   &lt;chr&gt;                    &lt;dbl&gt;\n 1 Alabama                    8.6\n 2 Alaska                     5.3\n 3 Arizona                    6  \n 4 Arkansas                   8.3\n 5 California                12.6\n 6 Colorado                   5.7\n 7 Connecticut                7.8\n 8 Delaware                   7.3\n 9 District of Columbia       7.8\n10 Florida                    7.9\n# ℹ 41 more rows\n\n\nRows: 51 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): State\nnum (2): Number of Wildfires, Acres Burned\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 51 × 3\n   State          `Number of Wildfires` `Acres Burned`\n   &lt;chr&gt;                          &lt;dbl&gt;          &lt;dbl&gt;\n 1 California                      7364         332722\n 2 Texas                           7102         210264\n 3 North Carolina                  5214          73953\n 4 Florida                         2730          99642\n 5 Georgia                         2386          10330\n 6 Mississippi                     2383          52508\n 7 Oregon                          1979         202035\n 8 Pennsylvania                    1910           9628\n 9 Alabama                         1856          18335\n10 Arizona                         1837         188483\n# ℹ 41 more rows\n\n\nOverview These choropleth maps use state level data to illustrate pollution (micrograms per cubic) and the [BLANK]. The first dataset looks at air pollution and particulate matter by state in the year 2020.\n\n\n\n\n\n\n\n\n\nvia the NIH (National Institute on Minority Health and Health Disparities)\nInsights: This plot shows the pollution trends across the continuous United States in the year 2020. The darker colors show states that are more polluted (higher micrograms per meter). While the lighter colors shows tates that are less polluted (lower micrograms per meter).\n\n\nWarning: sf layer has inconsistent datum (+proj=longlat +ellps=clrk66 +no_defs).\nNeed '+proj=longlat +datum=WGS84'\n\n\n\n\n\n\nVia the NHS ((National Institute on Minority Health and Health Disparities))\nInsights: This plot is very similar to the plot above as it still shows the same pollution trends across the continuous United States. However the plot is now more interactive then the previous. By hovering over a particular state we can see what the actual micrograms per cubic meter value is."
  }
]